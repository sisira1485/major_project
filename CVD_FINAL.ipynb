{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80e27221",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e68d70e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>General_Health</th>\n",
       "      <th>Checkup</th>\n",
       "      <th>Exercise</th>\n",
       "      <th>Heart_Disease</th>\n",
       "      <th>Skin_Cancer</th>\n",
       "      <th>Other_Cancer</th>\n",
       "      <th>Depression</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>Arthritis</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age_Category</th>\n",
       "      <th>Height_(cm)</th>\n",
       "      <th>Weight_(kg)</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoking_History</th>\n",
       "      <th>Alcohol_Consumption</th>\n",
       "      <th>Fruit_Consumption</th>\n",
       "      <th>Green_Vegetables_Consumption</th>\n",
       "      <th>FriedPotato_Consumption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Poor</td>\n",
       "      <td>Within the past 2 years</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Female</td>\n",
       "      <td>70-74</td>\n",
       "      <td>150.0</td>\n",
       "      <td>32.66</td>\n",
       "      <td>14.54</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Very Good</td>\n",
       "      <td>Within the past year</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Female</td>\n",
       "      <td>70-74</td>\n",
       "      <td>165.0</td>\n",
       "      <td>77.11</td>\n",
       "      <td>28.29</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Very Good</td>\n",
       "      <td>Within the past year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Female</td>\n",
       "      <td>60-64</td>\n",
       "      <td>163.0</td>\n",
       "      <td>88.45</td>\n",
       "      <td>33.47</td>\n",
       "      <td>No</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Poor</td>\n",
       "      <td>Within the past year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>75-79</td>\n",
       "      <td>180.0</td>\n",
       "      <td>93.44</td>\n",
       "      <td>28.73</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Good</td>\n",
       "      <td>Within the past year</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>80+</td>\n",
       "      <td>191.0</td>\n",
       "      <td>88.45</td>\n",
       "      <td>24.37</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  General_Health                  Checkup Exercise Heart_Disease Skin_Cancer  \\\n",
       "0           Poor  Within the past 2 years       No            No          No   \n",
       "1      Very Good     Within the past year       No           Yes          No   \n",
       "2      Very Good     Within the past year      Yes            No          No   \n",
       "3           Poor     Within the past year      Yes           Yes          No   \n",
       "4           Good     Within the past year       No            No          No   \n",
       "\n",
       "  Other_Cancer Depression Diabetes Arthritis     Sex Age_Category  \\\n",
       "0           No         No       No       Yes  Female        70-74   \n",
       "1           No         No      Yes        No  Female        70-74   \n",
       "2           No         No      Yes        No  Female        60-64   \n",
       "3           No         No      Yes        No    Male        75-79   \n",
       "4           No         No       No        No    Male          80+   \n",
       "\n",
       "   Height_(cm)  Weight_(kg)    BMI Smoking_History  Alcohol_Consumption  \\\n",
       "0        150.0        32.66  14.54             Yes                  0.0   \n",
       "1        165.0        77.11  28.29              No                  0.0   \n",
       "2        163.0        88.45  33.47              No                  4.0   \n",
       "3        180.0        93.44  28.73              No                  0.0   \n",
       "4        191.0        88.45  24.37             Yes                  0.0   \n",
       "\n",
       "   Fruit_Consumption  Green_Vegetables_Consumption  FriedPotato_Consumption  \n",
       "0               30.0                          16.0                     12.0  \n",
       "1               30.0                           0.0                      4.0  \n",
       "2               12.0                           3.0                     16.0  \n",
       "3               30.0                          30.0                      8.0  \n",
       "4                8.0                           4.0                      0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\shara\\OneDrive\\Desktop\\project\\CVD.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5d6af57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>General_Health</th>\n",
       "      <th>Checkup</th>\n",
       "      <th>Exercise</th>\n",
       "      <th>Heart_Disease</th>\n",
       "      <th>Skin_Cancer</th>\n",
       "      <th>Other_Cancer</th>\n",
       "      <th>Depression</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>Arthritis</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age_Category</th>\n",
       "      <th>Height_(cm)</th>\n",
       "      <th>Weight_(kg)</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoking_History</th>\n",
       "      <th>Alcohol_Consumption</th>\n",
       "      <th>Fruit_Consumption</th>\n",
       "      <th>Green_Vegetables_Consumption</th>\n",
       "      <th>FriedPotato_Consumption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>150.0</td>\n",
       "      <td>32.66</td>\n",
       "      <td>14.54</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>165.0</td>\n",
       "      <td>77.11</td>\n",
       "      <td>28.29</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>163.0</td>\n",
       "      <td>88.45</td>\n",
       "      <td>33.47</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>180.0</td>\n",
       "      <td>93.44</td>\n",
       "      <td>28.73</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>191.0</td>\n",
       "      <td>88.45</td>\n",
       "      <td>24.37</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   General_Health  Checkup  Exercise  Heart_Disease  Skin_Cancer  \\\n",
       "0               3        2         0              0            0   \n",
       "1               4        4         0              1            0   \n",
       "2               4        4         1              0            0   \n",
       "3               3        4         1              1            0   \n",
       "4               2        4         0              0            0   \n",
       "\n",
       "   Other_Cancer  Depression  Diabetes  Arthritis  Sex  Age_Category  \\\n",
       "0             0           0         0          1    0            10   \n",
       "1             0           0         2          0    0            10   \n",
       "2             0           0         2          0    0             8   \n",
       "3             0           0         2          0    1            11   \n",
       "4             0           0         0          0    1            12   \n",
       "\n",
       "   Height_(cm)  Weight_(kg)    BMI  Smoking_History  Alcohol_Consumption  \\\n",
       "0        150.0        32.66  14.54                1                  0.0   \n",
       "1        165.0        77.11  28.29                0                  0.0   \n",
       "2        163.0        88.45  33.47                0                  4.0   \n",
       "3        180.0        93.44  28.73                0                  0.0   \n",
       "4        191.0        88.45  24.37                1                  0.0   \n",
       "\n",
       "   Fruit_Consumption  Green_Vegetables_Consumption  FriedPotato_Consumption  \n",
       "0               30.0                          16.0                     12.0  \n",
       "1               30.0                           0.0                      4.0  \n",
       "2               12.0                           3.0                     16.0  \n",
       "3               30.0                          30.0                      8.0  \n",
       "4                8.0                           4.0                      0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Assuming 'df' is your DataFrame with categorical variables\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Iterate through each categorical column and transform the values\n",
    "for column in categorical_columns:\n",
    "    df[column] = label_encoder.fit_transform(df[column])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32087186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>General_Health</th>\n",
       "      <th>Checkup</th>\n",
       "      <th>Exercise</th>\n",
       "      <th>Heart_Disease</th>\n",
       "      <th>Skin_Cancer</th>\n",
       "      <th>Other_Cancer</th>\n",
       "      <th>Depression</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>Arthritis</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age_Category</th>\n",
       "      <th>Height_(cm)</th>\n",
       "      <th>Weight_(kg)</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoking_History</th>\n",
       "      <th>Alcohol_Consumption</th>\n",
       "      <th>Fruit_Consumption</th>\n",
       "      <th>Green_Vegetables_Consumption</th>\n",
       "      <th>FriedPotato_Consumption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.393333</td>\n",
       "      <td>0.028761</td>\n",
       "      <td>0.028863</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.09375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.493333</td>\n",
       "      <td>0.194576</td>\n",
       "      <td>0.186347</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.03125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.236878</td>\n",
       "      <td>0.245676</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.12500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.593333</td>\n",
       "      <td>0.255493</td>\n",
       "      <td>0.191387</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.234375</td>\n",
       "      <td>0.06250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.236878</td>\n",
       "      <td>0.141450</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   General_Health  Checkup  Exercise  Heart_Disease  Skin_Cancer  \\\n",
       "0            0.75      0.5       0.0            0.0          0.0   \n",
       "1            1.00      1.0       0.0            1.0          0.0   \n",
       "2            1.00      1.0       1.0            0.0          0.0   \n",
       "3            0.75      1.0       1.0            1.0          0.0   \n",
       "4            0.50      1.0       0.0            0.0          0.0   \n",
       "\n",
       "   Other_Cancer  Depression  Diabetes  Arthritis  Sex  Age_Category  \\\n",
       "0           0.0         0.0  0.000000        1.0  0.0      0.833333   \n",
       "1           0.0         0.0  0.666667        0.0  0.0      0.833333   \n",
       "2           0.0         0.0  0.666667        0.0  0.0      0.666667   \n",
       "3           0.0         0.0  0.666667        0.0  1.0      0.916667   \n",
       "4           0.0         0.0  0.000000        0.0  1.0      1.000000   \n",
       "\n",
       "   Height_(cm)  Weight_(kg)       BMI  Smoking_History  Alcohol_Consumption  \\\n",
       "0     0.393333     0.028761  0.028863              1.0             0.000000   \n",
       "1     0.493333     0.194576  0.186347              0.0             0.000000   \n",
       "2     0.480000     0.236878  0.245676              0.0             0.133333   \n",
       "3     0.593333     0.255493  0.191387              0.0             0.000000   \n",
       "4     0.666667     0.236878  0.141450              1.0             0.000000   \n",
       "\n",
       "   Fruit_Consumption  Green_Vegetables_Consumption  FriedPotato_Consumption  \n",
       "0           0.250000                      0.125000                  0.09375  \n",
       "1           0.250000                      0.000000                  0.03125  \n",
       "2           0.100000                      0.023438                  0.12500  \n",
       "3           0.250000                      0.234375                  0.06250  \n",
       "4           0.066667                      0.031250                  0.00000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Assuming 'df' is your original DataFrame\n",
    "original_df = pd.DataFrame(df)\n",
    "\n",
    "# Create a copy to keep the original data\n",
    "original_df_copy = original_df.copy()\n",
    "\n",
    "# Define min-max scaler with range 0 to \n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# Transform the data\n",
    "df_scaled = scaler.fit_transform(original_df_copy)\n",
    "\n",
    "# Convert the scaled data back to a DataFrame\n",
    "df_scaled = pd.DataFrame(df_scaled, columns=original_df_copy.columns)\n",
    "\n",
    "# Replace the original DataFrame 'df' with the scaled data\n",
    "df = df_scaled.copy()\n",
    "\n",
    "# Now, 'df' contains the scaled data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fed8ea0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "General_Health                  0\n",
      "Checkup                         0\n",
      "Exercise                        0\n",
      "Heart_Disease                   0\n",
      "Skin_Cancer                     0\n",
      "Other_Cancer                    0\n",
      "Depression                      0\n",
      "Diabetes                        0\n",
      "Arthritis                       0\n",
      "Sex                             0\n",
      "Age_Category                    0\n",
      "Height_(cm)                     0\n",
      "Weight_(kg)                     0\n",
      "BMI                             0\n",
      "Smoking_History                 0\n",
      "Alcohol_Consumption             0\n",
      "Fruit_Consumption               0\n",
      "Green_Vegetables_Consumption    0\n",
      "FriedPotato_Consumption         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Counting NaN values in all columns\n",
    "nan_count = df.isna().sum()\n",
    "\n",
    "print(nan_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d966042",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Heart_Disease']\n",
    "X = df.drop('Heart_Disease', axis=1, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f34b0184",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(X, columns=['General_Health', 'Checkup',\n",
    "                              'Exercise', 'Skin_Cancer', 'Other_Cancer', 'Depression',\n",
    "                              'Diabetes', 'Arthritis', 'Sex', 'Age_Category', 'Height_(cm)', 'Weight_(kg)',\n",
    "                              'BMI', 'Smoking_History', 'Alcohol_Consumption', 'Fruit_Consumption',\n",
    "                              'Green_Vegetables_Consumption','FriedPotato_Consumption'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a268f264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>General_Health</th>\n",
       "      <th>Checkup</th>\n",
       "      <th>Exercise</th>\n",
       "      <th>Skin_Cancer</th>\n",
       "      <th>Other_Cancer</th>\n",
       "      <th>Depression</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>Arthritis</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age_Category</th>\n",
       "      <th>Height_(cm)</th>\n",
       "      <th>Weight_(kg)</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoking_History</th>\n",
       "      <th>Alcohol_Consumption</th>\n",
       "      <th>Fruit_Consumption</th>\n",
       "      <th>Green_Vegetables_Consumption</th>\n",
       "      <th>FriedPotato_Consumption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.393333</td>\n",
       "      <td>0.028761</td>\n",
       "      <td>0.028863</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.09375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.493333</td>\n",
       "      <td>0.194576</td>\n",
       "      <td>0.186347</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.03125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.236878</td>\n",
       "      <td>0.245676</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.12500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.593333</td>\n",
       "      <td>0.255493</td>\n",
       "      <td>0.191387</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.234375</td>\n",
       "      <td>0.06250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.236878</td>\n",
       "      <td>0.141450</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   General_Health  Checkup  Exercise  Skin_Cancer  Other_Cancer  Depression  \\\n",
       "0            0.75      0.5       0.0          0.0           0.0         0.0   \n",
       "1            1.00      1.0       0.0          0.0           0.0         0.0   \n",
       "2            1.00      1.0       1.0          0.0           0.0         0.0   \n",
       "3            0.75      1.0       1.0          0.0           0.0         0.0   \n",
       "4            0.50      1.0       0.0          0.0           0.0         0.0   \n",
       "\n",
       "   Diabetes  Arthritis  Sex  Age_Category  Height_(cm)  Weight_(kg)       BMI  \\\n",
       "0  0.000000        1.0  0.0      0.833333     0.393333     0.028761  0.028863   \n",
       "1  0.666667        0.0  0.0      0.833333     0.493333     0.194576  0.186347   \n",
       "2  0.666667        0.0  0.0      0.666667     0.480000     0.236878  0.245676   \n",
       "3  0.666667        0.0  1.0      0.916667     0.593333     0.255493  0.191387   \n",
       "4  0.000000        0.0  1.0      1.000000     0.666667     0.236878  0.141450   \n",
       "\n",
       "   Smoking_History  Alcohol_Consumption  Fruit_Consumption  \\\n",
       "0              1.0             0.000000           0.250000   \n",
       "1              0.0             0.000000           0.250000   \n",
       "2              0.0             0.133333           0.100000   \n",
       "3              0.0             0.000000           0.250000   \n",
       "4              1.0             0.000000           0.066667   \n",
       "\n",
       "   Green_Vegetables_Consumption  FriedPotato_Consumption  \n",
       "0                      0.125000                  0.09375  \n",
       "1                      0.000000                  0.03125  \n",
       "2                      0.023438                  0.12500  \n",
       "3                      0.234375                  0.06250  \n",
       "4                      0.031250                  0.00000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6460f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1,stratify=y, random_state=0)\n",
    "\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b901081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Counts after SMOTE:\n",
      "Heart_Disease\n",
      "0    255494\n",
      "1    255494\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming y_resampled is your target variable after applying SMOTE\n",
    "y_resampled_series = pd.Series(y_resampled)\n",
    "\n",
    "# Print the count of each class\n",
    "print(\"Class Counts after SMOTE:\")\n",
    "print(y_resampled_series.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10a7ceb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9179239785015865\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.99      0.96     28389\n",
      "         1.0       0.45      0.06      0.11      2497\n",
      "\n",
      "    accuracy                           0.92     30886\n",
      "   macro avg       0.68      0.53      0.53     30886\n",
      "weighted avg       0.88      0.92      0.89     30886\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "xgb = XGBClassifier(random_state=42)\n",
    "xgb.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred_xgb)\n",
    "classification_rep = classification_report(y_test, y_pred_xgb)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ccff96c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8288628801989207"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_test, xgb.predict_proba(X_test)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1413f380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[28195   194]\n",
      " [ 2341   156]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1569f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 255494, number of negative: 255494\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.075236 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1825\n",
      "[LightGBM] [Info] Number of data points in the train set: 510988, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "LightGBM Classifier:\n",
      "Accuracy: 0.9009583630123681\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95     28389\n",
      "           1       0.27      0.14      0.18      2497\n",
      "\n",
      "    accuracy                           0.90     30886\n",
      "   macro avg       0.60      0.55      0.56     30886\n",
      "weighted avg       0.87      0.90      0.89     30886\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize and train LGBMClassifier\n",
    "lgbm_model = LGBMClassifier(random_state=42)\n",
    "lgbm_model.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_lgbm = lgbm_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_lgbm = accuracy_score(y_test, y_pred_lgbm)\n",
    "classification_rep_lgbm = classification_report(y_test, y_pred_lgbm)\n",
    "\n",
    "# Print the results for LGBMClassifier\n",
    "print(\"LightGBM Classifier:\")\n",
    "print(\"Accuracy:\", accuracy_lgbm)\n",
    "print(\"Classification Report:\\n\", classification_rep_lgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "387b48d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8312683170066506"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_test, lgbm_model.predict_proba(X_test)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f3c52d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[27488   901]\n",
      " [ 2158   339]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(y_test, y_pred_lgbm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09faca53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier:\n",
      "Accuracy: 0.8832156964320405\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94     28389\n",
      "           1       0.24      0.20      0.22      2497\n",
      "\n",
      "    accuracy                           0.88     30886\n",
      "   macro avg       0.58      0.57      0.58     30886\n",
      "weighted avg       0.87      0.88      0.88     30886\n",
      "\n",
      "Confusion Matrix\n",
      "[[27454   935]\n",
      " [ 2112   385]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize and train RandomForestClassifier with n_estimators=1000\n",
    "rf_model = RandomForestClassifier(random_state=0)\n",
    "rf_model.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "classification_rep_rf = classification_report(y_test, y_pred_rf)\n",
    "\n",
    "# Print the results for RandomForestClassifier\n",
    "print(\"Random Forest Classifier:\")\n",
    "print(\"Accuracy:\", accuracy_rf)\n",
    "print(\"Classification Report:\\n\", classification_rep_rf)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d1a8e78e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8127512922513251"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_test, rf_model.predict_proba(X_test)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0096aabf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[27729   660]\n",
      " [ 2115   382]]\n"
     ]
    }
   ],
   "source": [
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19ce43ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier:\n",
      "Accuracy: 0.9110600271967881\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.98      0.95     28389\n",
      "         1.0       0.38      0.15      0.22      2497\n",
      "\n",
      "    accuracy                           0.91     30886\n",
      "   macro avg       0.65      0.57      0.59     30886\n",
      "weighted avg       0.88      0.91      0.89     30886\n",
      "\n",
      "Confusion Matrix\n",
      "[[28195   194]\n",
      " [ 2341   156]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize and train RandomForestClassifier with n_estimators=1000\n",
    "rf1_model = RandomForestClassifier(random_state=0,n_estimators=1000)\n",
    "rf1_model.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_rf1 = rf1_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_rf1 = accuracy_score(y_test, y_pred_rf1)\n",
    "classification_rep_rf1 = classification_report(y_test, y_pred_rf1)\n",
    "\n",
    "# Print the results for RandomForestClassifier\n",
    "print(\"Random Forest Classifier:\")\n",
    "print(\"Accuracy:\", accuracy_rf1)\n",
    "print(\"Classification Report:\\n\", classification_rep_rf1)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a0813ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Model Accuracy: 0.9191543093958428\n",
      "Lasso Model Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      1.00      0.96     28389\n",
      "         1.0       0.00      0.00      0.00      2497\n",
      "\n",
      "    accuracy                           0.92     30886\n",
      "   macro avg       0.46      0.50      0.48     30886\n",
      "weighted avg       0.84      0.92      0.88     30886\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shara\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shara\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shara\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "# Initialize and train Lasso model\n",
    "lasso_model = Lasso(alpha=0.1, random_state=42)  # Adjust alpha based on your requirements\n",
    "lasso_model.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_lasso = lasso_model.predict(X_test)\n",
    "y_pred_lasso_binary = (y_pred_lasso > 0.1).astype(int)\n",
    "\n",
    "# Evaluate the Lasso model\n",
    "accuracy_lasso = accuracy_score(y_test, y_pred_lasso_binary)\n",
    "classification_rep_lasso = classification_report(y_test, y_pred_lasso_binary)\n",
    "\n",
    "print(\"Lasso Model Accuracy:\", accuracy_lasso)\n",
    "print(\"Lasso Model Classification Report:\\n\", classification_rep_lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "57b41853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 255480, number of negative: 255480\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.090726 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2851\n",
      "[LightGBM] [Info] Number of data points in the train set: 510960, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498740 -> initscore=-0.005042\n",
      "[LightGBM] [Info] Start training from score -0.005042\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 255480, number of negative: 255480\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.087448 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2850\n",
      "[LightGBM] [Info] Number of data points in the train set: 510960, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499693 -> initscore=-0.001229\n",
      "[LightGBM] [Info] Start training from score -0.001229\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 255480, number of negative: 255480\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.111416 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2847\n",
      "[LightGBM] [Info] Number of data points in the train set: 510960, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501640 -> initscore=0.006560\n",
      "[LightGBM] [Info] Start training from score 0.006560\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 255480, number of negative: 255480\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.092913 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2847\n",
      "[LightGBM] [Info] Number of data points in the train set: 510960, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499724 -> initscore=-0.001104\n",
      "[LightGBM] [Info] Start training from score -0.001104\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 255480, number of negative: 255480\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.079784 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2845\n",
      "[LightGBM] [Info] Number of data points in the train set: 510960, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499137 -> initscore=-0.003452\n",
      "[LightGBM] [Info] Start training from score -0.003452\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 255480, number of negative: 255480\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.110016 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2850\n",
      "[LightGBM] [Info] Number of data points in the train set: 510960, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500570 -> initscore=0.002278\n",
      "[LightGBM] [Info] Start training from score 0.002278\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 255480, number of negative: 255480\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.093617 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2848\n",
      "[LightGBM] [Info] Number of data points in the train set: 510960, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499280 -> initscore=-0.002881\n",
      "[LightGBM] [Info] Start training from score -0.002881\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 255480, number of negative: 255480\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.169916 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2850\n",
      "[LightGBM] [Info] Number of data points in the train set: 510960, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500767 -> initscore=0.003069\n",
      "[LightGBM] [Info] Start training from score 0.003069\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 255480, number of negative: 255480\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.151468 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2846\n",
      "[LightGBM] [Info] Number of data points in the train set: 510960, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499853 -> initscore=-0.000587\n",
      "[LightGBM] [Info] Start training from score -0.000587\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 255480, number of negative: 255480\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.102226 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2849\n",
      "[LightGBM] [Info] Number of data points in the train set: 510960, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499309 -> initscore=-0.002763\n",
      "[LightGBM] [Info] Start training from score -0.002763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "XGBoost Bagging Model Accuracy: 0.9189276694942693\n",
      "XGBoost Bagging Model Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.99      0.96     28403\n",
      "         1.0       0.47      0.06      0.10      2483\n",
      "\n",
      "    accuracy                           0.92     30886\n",
      "   macro avg       0.69      0.53      0.53     30886\n",
      "weighted avg       0.89      0.92      0.89     30886\n",
      "\n",
      "\n",
      "RandomForest Bagging Model Accuracy: 0.9065272291653176\n",
      "RandomForest Bagging Model Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.97      0.95     28403\n",
      "         1.0       0.35      0.20      0.25      2483\n",
      "\n",
      "    accuracy                           0.91     30886\n",
      "   macro avg       0.64      0.58      0.60     30886\n",
      "weighted avg       0.89      0.91      0.89     30886\n",
      "\n",
      "\n",
      "LightGBM Bagging Model Accuracy: 0.9190571780094541\n",
      "LightGBM Bagging Model Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      1.00      0.96     28403\n",
      "         1.0       0.47      0.05      0.09      2483\n",
      "\n",
      "    accuracy                           0.92     30886\n",
      "   macro avg       0.70      0.52      0.52     30886\n",
      "weighted avg       0.89      0.92      0.89     30886\n",
      "\n",
      "\n",
      "AdaBoost Bagging Model Accuracy: 0.821925791620799\n",
      "AdaBoost Bagging Model Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.85      0.90     28403\n",
      "         1.0       0.24      0.55      0.33      2483\n",
      "\n",
      "    accuracy                           0.82     30886\n",
      "   macro avg       0.60      0.70      0.61     30886\n",
      "weighted avg       0.90      0.82      0.85     30886\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Assuming you have already defined best_params for XGBoost, RandomForest, and LGBM\n",
    "\n",
    "# Create base models with the best hyperparameters\n",
    "xgb_base_model = XGBClassifier(**best_params)\n",
    "rf_base_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "lgbm_base_model = LGBMClassifier(**best_params)\n",
    "adaboost_base_model = AdaBoostClassifier(n_estimators=50, random_state=42)\n",
    "\n",
    "# Initialize BaggingClassifier with each base model\n",
    "xgb_bagging_model = BaggingClassifier(xgb_base_model, n_estimators=10, random_state=42)\n",
    "rf_bagging_model = BaggingClassifier(rf_base_model, n_estimators=10, random_state=42)\n",
    "lgbm_bagging_model = BaggingClassifier(lgbm_base_model, n_estimators=10, random_state=42)\n",
    "adaboost_bagging_model = BaggingClassifier(adaboost_base_model, n_estimators=10, random_state=42)\n",
    "\n",
    "# Fit the bagging models on the resampled data\n",
    "xgb_bagging_model.fit(X_resampled, y_resampled)\n",
    "rf_bagging_model.fit(X_resampled, y_resampled)\n",
    "lgbm_bagging_model.fit(X_resampled, y_resampled)\n",
    "adaboost_bagging_model.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_xgb_bagging = xgb_bagging_model.predict(X_test)\n",
    "y_pred_rf_bagging = rf_bagging_model.predict(X_test)\n",
    "y_pred_lgbm_bagging = lgbm_bagging_model.predict(X_test)\n",
    "y_pred_adaboost_bagging = adaboost_bagging_model.predict(X_test)\n",
    "\n",
    "# Evaluate the bagging models\n",
    "accuracy_xgb_bagging = accuracy_score(y_test, y_pred_xgb_bagging)\n",
    "accuracy_rf_bagging = accuracy_score(y_test, y_pred_rf_bagging)\n",
    "accuracy_lgbm_bagging = accuracy_score(y_test, y_pred_lgbm_bagging)\n",
    "accuracy_adaboost_bagging = accuracy_score(y_test, y_pred_adaboost_bagging)\n",
    "\n",
    "classification_rep_xgb_bagging = classification_report(y_test, y_pred_xgb_bagging)\n",
    "classification_rep_rf_bagging = classification_report(y_test, y_pred_rf_bagging)\n",
    "classification_rep_lgbm_bagging = classification_report(y_test, y_pred_lgbm_bagging)\n",
    "classification_rep_adaboost_bagging = classification_report(y_test, y_pred_adaboost_bagging)\n",
    "\n",
    "# Print the results\n",
    "print(\"XGBoost Bagging Model Accuracy:\", accuracy_xgb_bagging)\n",
    "print(\"XGBoost Bagging Model Classification Report:\\n\", classification_rep_xgb_bagging)\n",
    "\n",
    "print(\"\\nRandomForest Bagging Model Accuracy:\", accuracy_rf_bagging)\n",
    "print(\"RandomForest Bagging Model Classification Report:\\n\", classification_rep_rf_bagging)\n",
    "\n",
    "print(\"\\nLightGBM Bagging Model Accuracy:\", accuracy_lgbm_bagging)\n",
    "print(\"LightGBM Bagging Model Classification Report:\\n\", classification_rep_lgbm_bagging)\n",
    "\n",
    "print(\"\\nAdaBoost Bagging Model Accuracy:\", accuracy_adaboost_bagging)\n",
    "print(\"AdaBoost Bagging Model Classification Report:\\n\", classification_rep_adaboost_bagging)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "16a89f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 255480, number of negative: 255480\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.078329 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2849\n",
      "[LightGBM] [Info] Number of data points in the train set: 510960, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Voting Model Accuracy: 0.9103153532344752\n",
      "Voting Model Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.98      0.95     28403\n",
      "         1.0       0.33      0.12      0.17      2483\n",
      "\n",
      "    accuracy                           0.91     30886\n",
      "   macro avg       0.63      0.55      0.56     30886\n",
      "weighted avg       0.88      0.91      0.89     30886\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "# Initialize base models with different variable names\n",
    "xgb_classifier = XGBClassifier(**best_params)  # Assuming you have best_params defined\n",
    "random_forest_classifier = RandomForestClassifier(random_state=42)\n",
    "lgbm_classifier = LGBMClassifier(**best_params)  # Assuming you have best_params defined\n",
    "adaboost_classifier = AdaBoostClassifier(n_estimators=50, random_state=42)\n",
    "decision_tree_classifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Create a VotingClassifier with multiple base models\n",
    "voting_model = VotingClassifier(estimators=[\n",
    "    ('xgb', xgb_classifier),\n",
    "    ('rf', random_forest_classifier),\n",
    "    ('lgbm', lgbm_classifier),\n",
    "    ('adaboost', adaboost_classifier),\n",
    "    ('dt', decision_tree_classifier),\n",
    "], voting='soft')  # Use 'soft' for probability-based voting\n",
    "\n",
    "# Fit the voting model on the resampled data\n",
    "voting_model.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_voting = voting_model.predict(X_test)\n",
    "\n",
    "# Evaluate the voting model\n",
    "accuracy_voting = accuracy_score(y_test, y_pred_voting)\n",
    "classification_rep_voting = classification_report(y_test, y_pred_voting)\n",
    "\n",
    "print(\"Voting Model Accuracy:\", accuracy_voting)\n",
    "print(\"Voting Model Classification Report:\\n\", classification_rep_voting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aa48ff7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 255480, number of negative: 255480\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045840 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2849\n",
      "[LightGBM] [Info] Number of data points in the train set: 510960, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 204384, number of negative: 204384\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.073859 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2855\n",
      "[LightGBM] [Info] Number of data points in the train set: 408768, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 204384, number of negative: 204384\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.067795 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2853\n",
      "[LightGBM] [Info] Number of data points in the train set: 408768, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 204384, number of negative: 204384\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.073401 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2849\n",
      "[LightGBM] [Info] Number of data points in the train set: 408768, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 204384, number of negative: 204384\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.065589 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2848\n",
      "[LightGBM] [Info] Number of data points in the train set: 408768, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 204384, number of negative: 204384\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.066856 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2845\n",
      "[LightGBM] [Info] Number of data points in the train set: 408768, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Stacking Model Accuracy: 0.9070452632260572\n",
      "Stacking Model Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.97      0.95     28403\n",
      "         1.0       0.35      0.17      0.23      2483\n",
      "\n",
      "    accuracy                           0.91     30886\n",
      "   macro avg       0.64      0.57      0.59     30886\n",
      "weighted avg       0.88      0.91      0.89     30886\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier, RandomForestClassifier, AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "# Initialize base models with different variable names\n",
    "xgb_clf = XGBClassifier(**best_params)  # Assuming you have best_params defined\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "lgbm_clf = LGBMClassifier(**best_params)  # Assuming you have best_params defined\n",
    "adaboost_clf = AdaBoostClassifier(n_estimators=50, random_state=42)\n",
    "custom_dt_clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Initialize StackingClassifier with base models and a Logistic Regression meta-model\n",
    "stacking_model = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('xgb', xgb_clf),\n",
    "        ('rf', rf_clf),\n",
    "        ('lgbm', lgbm_clf),\n",
    "        ('adaboost', adaboost_clf),\n",
    "        ('dt', custom_dt_clf),\n",
    "    ],\n",
    "    final_estimator=LogisticRegression(),\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "# Fit the stacking model on the resampled data\n",
    "stacking_model.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_stacking = stacking_model.predict(X_test)\n",
    "\n",
    "# Evaluate the stacking model\n",
    "accuracy_stacking = accuracy_score(y_test, y_pred_stacking)\n",
    "classification_rep_stacking = classification_report(y_test, y_pred_stacking)\n",
    "\n",
    "print(\"Stacking Model Accuracy:\", accuracy_stacking)\n",
    "print(\"Stacking Model Classification Report:\\n\", classification_rep_stacking)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "934ecd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b117198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200, 'subsample': 0.9}\n",
      "Accuracy: 0.9191219322670465\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.99      0.96     28403\n",
      "         1.0       0.48      0.07      0.12      2483\n",
      "\n",
      "    accuracy                           0.92     30886\n",
      "   macro avg       0.70      0.53      0.54     30886\n",
      "weighted avg       0.89      0.92      0.89     30886\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "best_model_xgb1 = XGBClassifier(**best_params)\n",
    "best_model_xgb1.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_predxgb1 = best_model_xgb1.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracyxgb1 = accuracy_score(y_test, y_predxgb1)\n",
    "classification_repxgb1 = classification_report(y_test, y_predxgb1)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Accuracy:\", accuracyxgb1)\n",
    "print(\"Classification Report:\\n\", classification_repxgb1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0af318b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pickle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrained_model.sav\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 2\u001b[0m pickle\u001b[38;5;241m.\u001b[39mdump(best_model,\u001b[38;5;28mopen\u001b[39m(filename,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pickle' is not defined"
     ]
    }
   ],
   "source": [
    "filename='trained_model.sav'\n",
    "pickle.dump(best_model,open(filename,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6bf16ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model=pickle.load(open('trained_model.sav','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f37a8726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\shara\\anaconda\\lib\\site-packages (1.4.1.post1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.19.5 in c:\\users\\shara\\anaconda\\lib\\site-packages (from scikit-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\shara\\anaconda\\lib\\site-packages (from scikit-learn) (1.11.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\shara\\anaconda\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\shara\\anaconda\\lib\\site-packages (from scikit-learn) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aef8fd16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9179239785015865\n",
      "Precision: 0.44571428571428573\n",
      "Recall: 0.062474969963956746\n",
      "F1-Score: 0.1095890410958904\n",
      "Cohen's Kappa: 0.0915307062837325\n",
      "Matthews Correlation Coefficient: 0.1432985453139362\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.99      0.96     28389\n",
      "         1.0       0.45      0.06      0.11      2497\n",
      "\n",
      "    accuracy                           0.92     30886\n",
      "   macro avg       0.68      0.53      0.53     30886\n",
      "weighted avg       0.88      0.92      0.89     30886\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score, cohen_kappa_score, matthews_corrcoef\n",
    "\n",
    "# Assuming X_resampled, y_resampled, X_test, y_test are defined\n",
    "\n",
    "xgb = XGBClassifier(random_state=42)\n",
    "xgb.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred_xgb)\n",
    "precision = precision_score(y_test, y_pred_xgb)\n",
    "recall = recall_score(y_test, y_pred_xgb)\n",
    "f1 = f1_score(y_test, y_pred_xgb)\n",
    "kappa = cohen_kappa_score(y_test, y_pred_xgb)\n",
    "mcc = matthews_corrcoef(y_test, y_pred_xgb)\n",
    "\n",
    "classification_rep = classification_report(y_test, y_pred_xgb)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-Score:\", f1)\n",
    "print(\"Cohen's Kappa:\", kappa)\n",
    "print(\"Matthews Correlation Coefficient:\", mcc)\n",
    "print(\"\\nClassification Report:\\n\", classification_rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780474b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "svm = SVC(random_state=42)\n",
    "svm.fit(X_resampled, y_resampled)\n",
    "\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "classification_rep_svm = classification_report(y_test, y_pred_svm)\n",
    "\n",
    "print(\"SVM Accuracy:\", accuracy_svm)\n",
    "print(\"SVM Classification Report:\\n\", classification_rep_svm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268f2843",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_resampled, y_resampled)\n",
    "\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "classification_rep_dt = classification_report(y_test, y_pred_dt)\n",
    "\n",
    "print(\"Decision Tree Accuracy:\", accuracy_dt)\n",
    "print(\"Decision Tree Classification Report:\\n\", classification_rep_dt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60653d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "lr = LogisticRegression(random_state=42)\n",
    "lr.fit(X_resampled, y_resampled)\n",
    "\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "classification_rep_lr = classification_report(y_test, y_pred_lr)\n",
    "\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_lr)\n",
    "print(\"Logistic Regression Classification Report:\\n\", classification_rep_lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591f5927",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_resampled, y_resampled)\n",
    "\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "classification_rep_knn = classification_report(y_test, y_pred_knn)\n",
    "\n",
    "print(\"KNN Accuracy:\", accuracy_knn)\n",
    "print(\"KNN Classification Report:\\n\", classification_rep_knn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7b15f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_resampled, y_resampled)\n",
    "\n",
    "y_pred_nb = nb.predict(X_test)\n",
    "\n",
    "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
    "classification_rep_nb = classification_report(y_test, y_pred_nb)\n",
    "\n",
    "print(\"Naive Bayes Accuracy:\", accuracy_nb)\n",
    "print(\"Naive Bayes Classification Report:\\n\", classification_rep_nb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4552323f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "gradient_boosting = GradientBoostingClassifier(random_state=42)\n",
    "gradient_boosting.fit(X_resampled, y_resampled)\n",
    "\n",
    "y_pred_gradient_boosting = gradient_boosting.predict(X_test)\n",
    "\n",
    "accuracy_gradient_boosting = accuracy_score(y_test, y_pred_gradient_boosting)\n",
    "classification_rep_gradient_boosting = classification_report(y_test, y_pred_gradient_boosting)\n",
    "\n",
    "print(\"Gradient Boosting Classifier Accuracy:\", accuracy_gradient_boosting)\n",
    "print(\"Gradient Boosting Classifier Classification Report:\\n\", classification_rep_gradient_boosting)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
